\section{Browser IDE Vergleich}
In diesem Abschnitt werden die drei Browser IDEs
github.dev \cite{githubDevWebsite},
stackblitz.com \cite{stackblitzcomWebsite},
und
gitpod.io \cite{gitpodioWebsite}
grob miteinander vergleichen.
Dabei wird auf den Editor und die wichtigsten Features eingegangen.

\subsection{github.dev}
% TODO

\subsection{stackblitz.com}
% TODO

\subsection{gitpod.io}
% TODO


\clearpage
\section{Dokumentation der Projektumsetzung}

\subsection{Schritt-für-Schritt-Anleitung}

\subsubsection{CI Pipeline \& Unit Tests}
Zuerst wird das Basis-Repository 
\url{https://github.com/t-stefan/FHB-Assignment-Backend}
im GitHub Webinterface
\url{https://github.com/new/import} 
importiert.

% TODO: search & replace all  thomasstxyz/fhb-mcce-tmcsp-assignment-backend  with <account/repository>

\noindent
Als nächstes müssen die GitHub Actions für das Repository unter
\url{https://github.com/thomasstxyz/fhb-mcce-tmcsp-assignment-backend/settings/actions}
aktiviert werden.
Wir wählen hierfür den Punkt \verb|Allow all actions and reusable workflows| aus
und drücken anschließend auf \verb|Save|. \\

\noindent
Nun kann zu \url{https://github.com/thomasstxyz/fhb-mcce-tmcsp-assignment-backend/actions/new}
navigiert werden.
Hier wählen wir den Workflow \verb|Node.js by GitHub Actions| 
(\url{https://github.com/thomasstxyz/fhb-mcce-tmcsp-assignment-backend/new/main?filename=.github%2Fworkflows%2Fnode.js.yml&workflow_template=node.js}).
Nun öffnet sich ein beispielhafter Workflow als neue Datei im Editor.
Mit \verb|Start commit| speichern wir diesen.
Anschließend kann zu \url{https://github.com/thomasstxyz/fhb-mcce-tmcsp-assignment-backend/actions/workflows/node.js.yml}
navigiert werden und der erste Durchlauf unseres Workflows live angesehen werden. \\

\noindent
Als nächsten Schritt laden wir unser Repository in einer gitpod.io Workspace
(\url{https://gitpod.io/#https://github.com/thomasstxyz/fhb-mcce-tmcsp-assignment-backend}).
Nachdem die Workspace fertig geladen ist, initialisieren wir mit 

\begin{verbatim}
	$ npm install
\end{verbatim}

\noindent
und starten die Applikation mit 
\begin{verbatim}
	$ npm start
\end{verbatim}

\noindent
Nun öffnen wir ein zweites Terminal und installieren Mocha
\cite{mochajsorgWebsite} mit dem Befehl

\begin{verbatim}
	$ npm install mocha --save-dev
\end{verbatim}

\noindent
Nach der Installation von Mocha, öffnen wir die Datei \verb|package.json|
und ändern den Wert von \verb|scripts.test| auf \verb|"mocha --exit"|.
Wir navigieren zum ursprünglichen Terminal, und brechen den Prozess mit der
Tastenkombination \verb|Ctrl+c| ab. \\

\noindent
Anschließend hängen wir folgende Zeile an das Ende der Datei \verb|index.js|:

\begin{verbatim}
	module.exports = app;
\end{verbatim}

\noindent
Weiters installieren wir das Modul \verb|superset|.

\begin{verbatim}
	$ npm install --save-dev supertest
\end{verbatim}

\noindent
Nun legen wir ein Verzeichnis namens \verb|test| an.
In diesem Verzeichnis legen wir eine Datei \verb|index.test.js| 
mit folgendem Inhalt an:

\begin{verbatim}
const request = require('supertest');
const app = require('../index');

describe('GET /', () => {
	it('should return "Hello World!"', () => {
		return request(app)
		.get('/')
		.expect('<h1>Hello World!</h1>')
	});
	
	it('should return error 404, if /nonexistentpath is requested', () => {
		return request(app)
		.get('/non/existent/path')
		.expect(404)
	});
});

describe('POST /api/notes', () => {
	it('should return json {"error":"content missing"}, if request body is missing', () => {
		return request(app)
		.post('/api/notes')
		.expect('{"error":"content missing"}')
	});
	let query = {
		content: "my super cool note",
		important: true
	}
	it('should return 200, if json was requested with content and important fields', () => {
		return request(app)
		.post('/api/notes')
		.set('Content-type', 'application/json')
		.send( query )
		.expect(200);
	});
});

describe('GET /api/notes', () => {
	it('should return 200 and Content-Type: application/json', () => {
		return request(app)
		.get('/api/notes')
		.expect(200)
		.expect('Content-Type',/json/)
	});
});

describe('GET /api/notes/:id', () => {
	it('should return 200 and known data, if existing item with id 1 is requested', () => {
		return request(app)
		.get('/api/notes/1')
		.expect(200)
		.expect('Content-Type',/json/)
		.expect('{"id":1,"content":"HTML is easy","date":"2022-01-10T17:30:31.098Z","important":true}')
	});
});
\end{verbatim}

\noindent
Dies sind unsere Tests, welche mit dem Befehl

\begin{verbatim}
	$ npm run test
\end{verbatim}

\noindent
ausgeführt werden können. \\

\noindent
Schließlich haben wir alle nötigen Änderungen vorgenommen.
Diese müssen nur noch von gitpod zurück ins Repository gepusht werden.

\begin{verbatim}
	$ git add .
	$ git commit -m "add unit tests with mocha and superset"
	$ git push
\end{verbatim}


\subsubsection{Linting}
Zuerst installieren wir die ESLint:

\begin{verbatim}
	$ npm install eslint --save-dev
\end{verbatim}

\noindent
Dann erstellen wir eine Konfigurationsdatei

\begin{verbatim}
	$ npm init @eslint/config
\end{verbatim}

\noindent
und folgen dem interaktiven Installations-Setup. \\

\noindent
Dies erzeugt die Datei \verb|.eslintrc.js| mit folgendem Inhalt:

\begin{verbatim}
module.exports = {
env: {
browser: true,
es2021: true,
},
extends: [
'airbnb-base',
],
parserOptions: {
ecmaVersion: 'latest',
sourceType: 'module',
},
rules: {
},
};
\end{verbatim}

\noindent
Jetzt kann der Lint-Prozess ausgeführt werden:

\begin{verbatim}
	$ npx eslint index.js
\end{verbatim}

\noindent
Mit \verb|--fix| können wir dem Programm sagen,
dass es versuchen soll, die Änderungen selbst
automatisch vorzunehmen.

\begin{verbatim}
	$ npx eslint --fix-dry-run index.js
	$ npx eslint --fix index.js
\end{verbatim}

\noindent
Schließlich lassen wir den Lint-Prozess in unserer
als Teil unserer CI Pipeline laufen.
Dazu fügen wir den Befehl in \verb|.github/workflows/node.js.yml|
direkt nach der Zeile mit \verb|npm ci| ein:

\begin{verbatim}
...
- run: npm ci
- run: npx eslint --fix-dry-run index.js
- run: npm run build --if-present
...
\end{verbatim}

\noindent
Als letztes müssen wir die Änderungen noch zurück in unser
Repository pushen.

\begin{verbatim}
$ git add .
$ git commit -m "add ESLint syntax & style linting to workflow"
$ git push
\end{verbatim}


\subsubsection{Dependabot version updates}
Dependabot kann für uns automatisch Versionen updaten.
Wir erstellen eine Datei \verb|.github/dependabot.yml| 
mit folgendem Inhalt:

\begin{verbatim}
version: 2
updates:
# Enable version updates for npm
- package-ecosystem: "npm"
# Look for `package.json` and `lock` files in the `root` directory
directory: "/"
# Check the npm registry for updates every day (weekdays)
schedule:
interval: "daily"
\end{verbatim}

\noindent
und pushen unsere Änderungen ins Repository:

\begin{verbatim}
$ git add .
$ git commit -m "add .github/dependabot.yml"
$ git push
\end{verbatim}

\noindent
Dependabot öffnet nun selbstständig Pull Requests,
welche die Versionen der npm-Pakete updaten.

\subsubsection{Statische Codeanalyse mit Sonarqube}
Hierfür öffnen wir \url{https://github.com/marketplace/sonarcloud}
im Browser und erstellen uns einen Account.
Anschließend wählen wir aus, auf welche Repositories
SonarCloud zugreifen darf.
Um eine Analyse zu starten wählen wir das gewünschte Projekt aus 
und klicken auf \verb|Set up|.
Danach wird das Projekt analysiert, dies kann abhängig von der Größe des Projekts einige Zeit in
Anspruch nehmen. \\

\noindent
Jetzt wollen wir die statische Code-Analyse in einem
GitHub Workflow als Teil unserer CI Pipeline definieren. \\

\noindent
Zuerst erstellen wir ein Authentication Token in 
SonarCloud \url{https://sonarcloud.io/account/security/}.
Dazu vergeben wir einen beliebigen Namen und bestätigen mit 
dem Button \verb|Generate|.
Danach wird unser Token ausgegeben. 
Dieses kopieren wir in unsere Zwischenablage.
Nun erstellen wir auf GitHub in unserem Repository
ein Secret unter \url{https://github.com/thomasstxyz/fhb-mcce-tmcsp-assignment-backend/settings/secrets/actions}.
Der Name muss dabei \verb|SONAR_TOKEN| entsprechen,
und als Value fügen wir unser Token aus der Zwischenablage ein. \\

\noindent
Nun legen wir eine neue Datei \verb|sonar-project.properties|
im Rootverzeichnis unserer Repository an, mit folgendem Inhalt:

\begin{verbatim}
sonar.organization=<replace with your SonarCloud organization key>
sonar.projectKey=<replace with the key generated when setting up the project on SonarCloud>

# relative paths to source directories. More details and properties are described
# in https://sonarcloud.io/documentation/project-administration/narrowing-the-focus/
sonar.sources=.
\end{verbatim}

\noindent
Die Variablen \verb|sonar.organization| und
\verb|sonar.projectKey| ändern wir.
Unseren SonarCloud Organization Key können wir unter
\url{https://sonarcloud.io/account/organizations}
einsehen. 
Den Project Key sehen wir uns ebenfalls im SonarCloud 
Web Interface an. \\

\noindent
Als nächstes legen wir die Datei
\verb|.github/workflows/static-code-analysis.yml| 
für den Workflow an, mit folgendem Inhalt:

\begin{verbatim}
on:
# Trigger analysis when pushing in main or pull requests, and when creating
# a pull request.
push:
branches:
- main
pull_request:
types: [opened, synchronize, reopened]
name: Main Workflow
jobs:
sonarcloud:
runs-on: ubuntu-latest
steps:
- uses: actions/checkout@v2
with:
# Disabling shallow clone is recommended for improving relevancy of reporting
fetch-depth: 0
- name: SonarCloud Scan
uses: sonarsource/sonarcloud-github-action@master
env:
GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
\end{verbatim}

\noindent
Schließlich pushen wir unsere Änderungen ins Repository:

\begin{verbatim}
$ git add .
$ git commit -m "add workflow for static code analysis with SonarCloud"
$ git push
\end{verbatim}







